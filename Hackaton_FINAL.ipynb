{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac9d19d",
   "metadata": {},
   "source": [
    "# Hackaton \n",
    "\n",
    "Welcome to this Hackaton! \n",
    "\n",
    "Today we are going to explore solar energy data to understand how solar energy is depending by several variables. We are going to build several prediction models to estimate the solar energy based on the variable forecast values. We will compare the prediction models to find the best model that fit our needs. Finally we are going to use this model to detect any potential anomaly detection in the solar energy measurement system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c886fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functional package for our project \n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge,LinearRegression\n",
    "import seaborn as sns\n",
    "from tensorflow import keras as ks\n",
    "%matplotlib inline\n",
    "std_figsize = (16,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c389ecd3",
   "metadata": {},
   "source": [
    "## 1. Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from csv file \n",
    "data = pd.read_csv('https://raw.githubusercontent.com/peppusnight/just_for_data/main/DS.csv')\n",
    "#filter only relevant data with energy not null \n",
    "data = data.loc[data.ISDAY.values>0.5,:]\n",
    "\n",
    "# Feature selection\n",
    "features = ['Radiation','HumRad','CloudRad','CLOUDCOVER','HUMIDITY','VISIBILITY',\n",
    "            'TEMPERATURE','WINDSPEED','SOLARANGLE','HOUR']\n",
    "# Target variable\n",
    "target = 'Energy'\n",
    "\n",
    "# Select data for training (df_X) and target variable (df_y)\n",
    "data = data.loc[:, features + [target]]\n",
    "df_X = data.loc[:, features]\n",
    "df_y = data['Energy']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c611e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data description \n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8673a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how our target looks like? \n",
    "sns.relplot(data=data, y= 'Energy', x='Radiation', hue='HOUR')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(std_figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some insight on the data plotting some histogram, \n",
    "# check the unit of measure and value range and distribution of each variable \n",
    "_ = data.hist(figsize=std_figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79fa11a",
   "metadata": {},
   "source": [
    "### 1.1 Correlation Analysis \n",
    "\n",
    "Evalaute the possible correlation between our target and the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some more closer look on Energy correlated variable \n",
    "f, ax = plt.subplots(2,2,sharey=True, figsize = std_figsize)\n",
    "ax[0,0].plot(df_X['Radiation'], df_y, '.')\n",
    "ax[0,0].set_xlabel('Radiation')\n",
    "ax[0,1].plot(df_X['VISIBILITY'], df_y, '.')\n",
    "ax[0,1].set_xlabel('VISIBILITY')\n",
    "ax[1,1].plot(df_X['TEMPERATURE'], df_y, '.')\n",
    "ax[1,1].set_xlabel('TEMPERATURE')\n",
    "ax[1,0].plot(df_X['SOLARANGLE'], df_y, '.')\n",
    "ax[1,0].set_xlabel('SOLARANGLE')\n",
    "for a in ax.ravel(): a.grid(True); a.set_ylabel('Energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b873de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get perception on correlation through heat map of the variables\n",
    "plt.figure(figsize=std_figsize)\n",
    "sns.heatmap(data.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e911a68",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "Evaluate if the data need to be normalized. It might happen that due to the different nature of the data, the values could be very different between each other and this could influence the coefficient of the regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d307c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test set split\n",
    "features = ['Radiation','CloudRad','TEMPERATURE','WINDSPEED','HOUR']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X[features].values, df_y.values, test_size=0.3, random_state=2021)\n",
    "\n",
    "# data normalization \n",
    "X_train_scaled = (X_train-np.mean(X_train,axis=0))/np.std(X_train,axis=0)\n",
    "X_test_scaled  = (X_test-np.mean(X_train,axis=0))/np.std(X_train,axis=0)\n",
    "y_train_scaled = (y_train-np.mean(y_train,axis=0))/np.std(y_train,axis=0)\n",
    "y_test_scaled  = (y_test-np.mean(y_train,axis=0))/np.std(y_train,axis=0)\n",
    "print('X_train number of points: ', len(X_train), 'which means ', len(X_train)/len(df_X[features])*100, '% of overall data')\n",
    "print('X_test number of points: ', len(X_test), 'which means ', len(X_test)/len(df_X[features])*100, '% of overall data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756844a",
   "metadata": {},
   "source": [
    "## 3. Models\n",
    "\n",
    "in this section we are going to see what kind of different model we can elaborate to predict the solar energy as function of several variables. Check what are the feature of each models with its pros and cons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82698dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Root Mean Square Error to evalaute the performance of your model \n",
    "df = pd.DataFrame(data = {'rmse_train': [],\n",
    "                                'mape_train': [],\n",
    "                                'rmse_test': [],\n",
    "                                'mape_test': []}, index = []).T\n",
    "\n",
    "def mean_absolute_percentage_error(y_true,y_pred):\n",
    "    abs_diff = np.abs(y_true-y_pred)/y_true\n",
    "    mape = np.mean(abs_diff)\n",
    "    return mape\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true,y_pred))\n",
    "\n",
    "def plot_results(y_train, y_test, X_train, X_test, model):\n",
    "    f,ax = plt.subplots(2,2,sharex='col', figsize=std_figsize)\n",
    "    ax[0,0].plot(y_train, '.-', label='Energy')\n",
    "    ax[0,0].plot(model.predict(X_train), '.-', label='Predicted')\n",
    "    ax[1,0].plot(y_train - model.predict(X_train).ravel(),'.-', label='Residuals')\n",
    "    ax[0,1].plot(y_test, '.-', label='Energy')\n",
    "    ax[0,1].plot(model.predict(X_test), '.-', label='Predicted')\n",
    "    ax[1,1].plot(y_test - model.predict(X_test).ravel(),'.-', label='Residuals')\n",
    "    ax[0,0].set_title('Training set')\n",
    "    ax[0,1].set_title('Test set')\n",
    "    for a in ax.ravel(): a.grid(True); a.legend(frameon=False);\n",
    "    plt.figure(figsize=std_figsize)\n",
    "    plt.scatter(y_test, model.predict(X_test).ravel())\n",
    "    plt.plot(y_test,y_test)\n",
    "    plt.xlabel('y_test')\n",
    "    plt.ylabel('predicted')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    rmse_train = rmse(y_train, model.predict(X_train))\n",
    "    mape_train = 100*mean_absolute_percentage_error(y_train, model.predict(X_train).ravel())\n",
    "    rmse_test  = rmse(y_test, model.predict(X_test))\n",
    "    mape_test  = 100*mean_absolute_percentage_error(y_test, model.predict(X_test).ravel())\n",
    "    print('RMSE on train set = {:.2f}'.format(rmse_train))\n",
    "    print('MAPE on train set = {:.2f} '.format(mape_train))\n",
    "    print('RMSE on test set = {:.2f}'.format(rmse_test))\n",
    "    print('MAPE on test set = {:.2f} '.format(mape_test))\n",
    "    \n",
    "    return rmse_train, mape_train, rmse_test,mape_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3eb9b",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858938b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "# Modify only this parameter!!!!!\n",
    "alpha  = 0 # Regularization parameter from 0 to Inf\n",
    "solver = 'auto' # Solver:  lbfgs, svd, cholesky, lsqr, sparse_cg\n",
    "tol = 0.0001 # Tolerance for convergence\n",
    "##############################\n",
    "\n",
    "# Fit the model\n",
    "model_linear = Ridge(alpha = alpha, tol=tol, solver=solver)\n",
    "model_linear.fit(X_train_scaled,y_train)\n",
    "# print(model_linear.coef_)\n",
    "# #evaluate linear model\n",
    "# model_linear.predict(X_test_scaled)\n",
    "\n",
    "df['RidgeLinear'] = plot_results(y_train, y_test, X_train_scaled, X_test_scaled, model_linear)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc88b2c",
   "metadata": {},
   "source": [
    "## Polynomial Regression Model\n",
    "\n",
    "we can leverage on Explicif feature mapping to bring our ourginal features into an higher dimensional space. We can map linear features into a space with a polynomial basis, so by fitting a linear model in k feature we are really fitting a polynomial to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9782cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit Polynomial Regression Model\n",
    "######################\n",
    "# Modify only this parameter!!!!!\n",
    "polynomial_order = 2 # no more than 4!!!!\n",
    "alpha  = 0 # Regularization parameter from 0 to Inf\n",
    "solver = 'auto' # Solver: lbfgs, svd, cholesky, lsqr, sparse_cg\n",
    "tol = 0.0001 # Tolerance for convergence\n",
    "######################\n",
    "\n",
    "model_polfeat = PolynomialFeatures(polynomial_order) # specify the degree of polynomial feature\n",
    "model_polfeat.fit(X_train_scaled)\n",
    "\n",
    "print(\"Model Feature: \",model_polfeat.get_params())\n",
    "print(\"Model Structure:\", model_polfeat.get_feature_names())\n",
    "\n",
    "X_train_poly = model_polfeat.fit_transform(X_train_scaled)\n",
    "X_test_poly = model_polfeat.fit_transform(X_test_scaled)\n",
    "\n",
    "#fit the model on training dataset \n",
    "model_lin_polfeat = Ridge(alpha = alpha, tol=tol, solver=solver)\n",
    "model_lin_polfeat.fit(X_train_poly,y_train)\n",
    "\n",
    "#evaluate PolynomialFeatures model on test dataset\n",
    "model_lin_polfeat.predict(X_test_poly)\n",
    "\n",
    "df['RidgePoly'] = plot_results(y_train, y_test, X_train_poly, X_test_poly, model_lin_polfeat)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1438aeda",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eaaf28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# Modify only these parameters!!!!\n",
    "max_depth = 2\n",
    "min_samples_leaf = 1\n",
    "ccp_alpha = 0.0\n",
    "################################\n",
    "\n",
    "model_DT = DecisionTreeRegressor(random_state=2021, \n",
    "                                 max_depth=max_depth, \n",
    "                                 min_samples_leaf = min_samples_leaf,\n",
    "                                 ccp_alpha=ccp_alpha)\n",
    "model_DT.fit(X_train, y_train)\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "_ = tree.plot_tree(model_DT,\n",
    "                   feature_names=features,\n",
    "                   class_names=True,\n",
    "                   filled=True)\n",
    "\n",
    "df['DecisionTree'] =plot_results(y_train, y_test, X_train, X_test, model_DT)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c7fa64",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b515eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN model creation\n",
    "#####################\n",
    "# Modify only these parameters!!!\n",
    "hidden_activation_function = 'relu' #options: relu softsign tanh\n",
    "hidden_layer_1 = 10\n",
    "hidden_layer_2 = 10\n",
    "hidden_layer_3 = 10\n",
    "epoch = 500\n",
    "#####################\n",
    "\n",
    "input_data_shape = (len(features),)\n",
    "dnn_model = ks.models.Sequential()\n",
    "dnn_model.add(ks.layers.Input(shape=input_data_shape, name = 'Input_Layer'))\n",
    "dnn_model.add(ks.layers.Dense(hidden_layer_1, activation=hidden_activation_function, name = 'Hidden_Layer_1'))\n",
    "dnn_model.add(ks.layers.Dense(hidden_layer_2, activation=hidden_activation_function, name = 'Hidden_Layer_2'))\n",
    "dnn_model.add(ks.layers.Dense(hidden_layer_3, activation=hidden_activation_function, name = 'Hidden_Layer_3'))\n",
    "dnn_model.add(ks.layers.Dense(1, name = 'Output_Layer'))\n",
    "dnn_model.summary()\n",
    "\n",
    "# NN Model Trainig\n",
    "optimizer = 'adam'\n",
    "loss_function = 'mean_absolute_error'\n",
    "metric =['accuracy']\n",
    "dnn_model.compile(optimizer = optimizer, loss= loss_function, metrics=metric)\n",
    "history = dnn_model.fit(X_train_scaled, y_train, epochs = epoch, verbose=0)\n",
    "\n",
    "df['NeuralNet'] = plot_results(y_train, y_test, X_train_scaled, X_test_scaled, dnn_model)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6624ca9",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa601562",
   "metadata": {},
   "source": [
    "## Anomaly Detection Model \n",
    "\n",
    "Based on your best model selected, detect a possible anomaly on a new dataset. What your model says? what your data are saying? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Use only the following codes!!! # NN, DecisionTree, Linear, PolyLinear\n",
    "model_selected = 'PolyLinear'\n",
    "##############################\n",
    "\n",
    "#import data from csv file \n",
    "data_AnomalDetect = pd.read_csv('https://raw.githubusercontent.com/peppusnight/just_for_data/main/DS_Anomaly_Version.csv')\n",
    "\n",
    "#selection of input values and measured value in field \n",
    "features = ['Radiation','CloudRad','TEMPERATURE','WINDSPEED','HOUR']\n",
    "\n",
    "X_model = data_AnomalDetect.loc[:, features]\n",
    "Y_meas = data_AnomalDetect['Energy']\n",
    "\n",
    "# data normalization to feed the model (normaliation according to training set on which model has been developed)\n",
    "X_model_scaled = (X_model-np.mean(X_train,axis=0))/np.std(X_train,axis=0)\n",
    "X_model_scaled_poly = model_polfeat.fit_transform(X_model_scaled)\n",
    "\n",
    "if model_selected=='NN':\n",
    "    Y_model = dnn_model.predict(X_model_scaled).ravel()\n",
    "elif model_selected=='DecisionTree':\n",
    "    Y_model = model_DT.predict(X_model)\n",
    "elif model_selected=='Linear':\n",
    "    Y_model = model_linear.predict(X_model_scaled)\n",
    "elif model_selected=='PolyLinear':\n",
    "    Y_model = model_lin_polfeat.predict(X_model_scaled_poly)\n",
    "\n",
    "Y_model[Y_model<0] = 0\n",
    "# Alm Threshold\n",
    "AlmThreshold = 100\n",
    "AlmThreshold = np.ones(len(data_AnomalDetect), dtype=float) * AlmThreshold\n",
    "\n",
    "alm = pd.DataFrame()\n",
    "\n",
    "#check for every point if they are in alarm\n",
    "for i in range(len(data_AnomalDetect)):\n",
    "    if abs(Y_meas[i]-Y_model[i])<100:\n",
    "        alm.loc[i,'Allarm']=0\n",
    "    else:\n",
    "        alm.loc[i,'Allarm']=100\n",
    "f,ax = plt.subplots(3,sharex='col', figsize=std_figsize)\n",
    "ax[0].plot(data_AnomalDetect.index, Y_meas , label='Energy')\n",
    "ax[0].plot(data_AnomalDetect.index, Y_model, label='Predicted')\n",
    "\n",
    "ax[1].plot(data_AnomalDetect.index,Y_meas - Y_model, label='Residuals')\n",
    "ax[1].plot(data_AnomalDetect.index, AlmThreshold, '--', label='Measured', color='r')\n",
    "ax[1].plot(data_AnomalDetect.index, -AlmThreshold, '--', label='Measured', color='r')\n",
    "\n",
    "ax[2].plot(data_AnomalDetect.index, alm, label='Alarm Trigger', color='r',)\n",
    "ax[2].set_title('Training set')\n",
    "ax[2].set_title('Test set')\n",
    "for a in ax.ravel(): a.grid(True); a.legend(frameon=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146a210",
   "metadata": {},
   "source": [
    "Where the alarm has been trigged? \n",
    "\n",
    "check the solution and see what are the data that has been artificially altered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0539029b",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this session we have seen how to interpretate your data, how to test different models and tune their parameters to get the most accurate model. Then we have seen how to use the model for application in anomaly detection. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
